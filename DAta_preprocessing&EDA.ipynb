{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whenever we start coding we always start with the importing of the libraries. My flow is that i will import the base libraries first and then will upload the other libraries when they are required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the base libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numpy is used to create the numpy arrays\n",
    "import pandas as pd # pandas is used to work with the dataset\n",
    "import matplotlib.pyplot  # is used to visualize the data\n",
    "# to run the cell either you can click on the run button or you can use shift+enter in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "# you need a variable to store the dataset and then you need an appropriate function of the pandas library to import that particular file\n",
    "# while importing the dataset we need to provide the comple path of the file. but since we have uploaded the file in our working we just need to give the file name\n",
    "df = pd.read_csv('Data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA - we try to know our dataset. try to get the complete info, missing values, outliers, frequency string/categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Country    10 non-null     object \n",
      " 1   Age        9 non-null      float64\n",
      " 2   Salary     9 non-null      float64\n",
      " 3   Purchased  10 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country      0\n",
       "Age          1\n",
       "Salary       1\n",
       "Purchased    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have another function to know the extact number of missing values in our dataset\n",
    "# isna function checks for the missing values and the sum fucntion accumulates the missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and median of the age column\n",
      "38.77777777777778\n",
      "38.0\n"
     ]
    }
   ],
   "source": [
    "print('mean and median of the age column')\n",
    "print(df['Age'].mean())\n",
    "print(df['Age'].median())\n",
    "# no outliers are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and median of the Salary column\n",
      "63777.77777777778\n",
      "61000.0\n"
     ]
    }
   ],
   "source": [
    "print('mean and median of the Salary column')\n",
    "print(df['Salary'].mean())\n",
    "print(df['Salary'].median())\n",
    "# rounding off the mean we have 64000 and the median is 61000 taking the difference:- 3000\n",
    "# since this 3000 is very less compared to the rest of the values we can say that there are no outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since our ML models can work only with the numeric values we need to know if our data set has categorical values present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency count for country column\n",
      "France     4\n",
      "Spain      3\n",
      "Germany    3\n",
      "Name: Country, dtype: int64\n",
      "frequency count for purchased column\n",
      "No     5\n",
      "Yes    5\n",
      "Name: Purchased, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# we have function to know the frequency of occurence for these categories\n",
    "print('frequency count for country column')\n",
    "print(df[\"Country\"].value_counts())\n",
    "print('frequency count for purchased column')\n",
    "print(df[\"Purchased\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrac the x and y from the dataset. For this we use iloc function and the values function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "x = df.iloc[:,:-1].values # values function is used to extract only values from the datafram and store them as ndarray\n",
    "y = df.iloc[:,-1].values\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we split the data set into training set and the test set we perform all option pre-processing steps if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# To care of the missing data the SimpleImputer class of the sklearn.impute module is used\n",
    "from sklearn.impute import SimpleImputer\n",
    "# as you all know if we want to use the functions of class we need to create the object of the class and use that object to call the functions\n",
    "# here we will the object of the SimpleImputer class to use its functions\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean') # startegy - 'median', 'most frequent(mode), 'constant'\n",
    "x[: , 1:3] = imputer.fit_transform(x[: , 1:3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder' , OneHotEncoder(),[0])], remainder='passthrough')\n",
    "x = ct.fit_transform(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## since y also have the categorical data in the form of yes and no, so we will encode it too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Since the y has label type data we will labelencoder to encode it\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22474487 -0.65465367 -0.65465367  0.75887436  0.74947325]\n",
      " [-0.81649658 -0.65465367  1.52752523 -1.71150388 -1.43817841]\n",
      " [-0.81649658  1.52752523 -0.65465367 -1.27555478 -0.89126549]\n",
      " [-0.81649658 -0.65465367  1.52752523 -0.11302384 -0.25320042]\n",
      " [-0.81649658  1.52752523 -0.65465367  0.17760889  0.        ]\n",
      " [ 1.22474487 -0.65465367 -0.65465367 -0.54897294 -0.52665688]\n",
      " [-0.81649658 -0.65465367  1.52752523  0.         -1.0735698 ]\n",
      " [ 1.22474487 -0.65465367 -0.65465367  1.34013983  1.38753832]\n",
      " [-0.81649658  1.52752523 -0.65465367  1.63077256  1.75214693]\n",
      " [ 1.22474487 -0.65465367 -0.65465367 -0.25834021  0.29371249]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n",
    "np.set_printoptions(suppress = True)\n",
    "print(x)\n",
    "# the data after scalling is stored in scientific notation to change it into a readable format\n",
    "# we use np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the x and y into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81649658  1.52752523 -0.65465367  0.17760889  0.        ]\n",
      " [ 1.22474487 -0.65465367 -0.65465367 -0.25834021  0.29371249]\n",
      " [-0.81649658 -0.65465367  1.52752523 -1.71150388 -1.43817841]\n",
      " [-0.81649658 -0.65465367  1.52752523  0.         -1.0735698 ]\n",
      " [ 1.22474487 -0.65465367 -0.65465367  1.34013983  1.38753832]\n",
      " [-0.81649658 -0.65465367  1.52752523 -0.11302384 -0.25320042]\n",
      " [ 1.22474487 -0.65465367 -0.65465367  0.75887436  0.74947325]\n",
      " [ 1.22474487 -0.65465367 -0.65465367 -0.54897294 -0.52665688]]\n",
      "[[-0.81649658  1.52752523 -0.65465367 -1.27555478 -0.89126549]\n",
      " [-0.81649658  1.52752523 -0.65465367  1.63077256  1.75214693]]\n",
      "[1 1 1 0 1 0 0 1]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# the train_test_split method is designed to split our x any inot training set and test set\n",
    "# giving four output. While splitting the x and y it shuffles the rows\n",
    "# to get the same shuffling for everyone we provide the shuffling state as the value if 'random_state' parameter\n",
    "# we also need to give the size of either the train_size or test_size, by default the ration is 75:25\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 0)\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 362.86,
   "position": {
    "height": "40px",
    "left": "195.85px",
    "right": "20px",
    "top": "58px",
    "width": "735px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
